#!/usr/bin/env python

#
# ddr-export
#

description = """Exports a DDR collection's entities or files to CSV."""

epilog = """
If CSV is not specified a filename will be generated in the form
COLLECTION-MODEL.csv and written to /tmp/.  For example:
    /tmp/ddr-test-123-entity.csv

Sample ID formats:
    ddr-test-123-*            All entities in a collection
    ddr-test-123-1-*          All files in an entity
    ddr-test-123-*            All files in a collection
    ddr-test-123-[1-5,7-8,10] Ranges of entities

Examples:

    $ ddr-export entity /var/www/media/base/ddr-testing-123 /tmp
    $ ddr-export file /var/www/media/base/ddr-testing-123 /tmp

You can also print out blank CSV files with all fields:

    $ ddr-export -b entity /var/www/media/base/ddr-testing-123 /tmp
    $ ddr-export -b file /var/www/media/base/ddr-testing-123 /tmp

And with only required fields:

    $ ddr-export -B entity /var/www/media/base/ddr-testing-123 /tmp
    $ ddr-export -B file /var/www/media/base/ddr-testing-123 /tmp

ddr-export"""


import argparse
from datetime import datetime
import logging
import os
import re
import sys

from DDR import batch_export
from DDR import identifier
from DDR import util

logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s %(levelname)-8s %(message)s',
    stream=sys.stdout,
)


def read_id_file(path):
    """Read file and return list of IDs
    
    @param path: str Absolute path to file.
    @returns: list of IDs
    """
    with open(path, 'r') as f:
        text = f.read()
    ids = [line.strip() for line in text.strip().split('\n')]
    return ids

def make_paths(collection_path, ids):
    """
    """
    basedir = os.path.dirname(collection_path)
    paths = [
        identifier.Identifier(object_id, basedir).path_abs('json')
        for object_id in ids
    ]
    return paths

def make_csv_path(destdir, collection_path, model):
    """Assemble path for CSV file.
    
    @param destdir: str Absolute path to destination dir
    @param collection_path: str Absolute path to collection repository
    @param model: str One of ['collection', 'entity', 'file']
    """
    filename = '%s-%s-%s.csv' % (
        identifier.Identifier(collection_path).id,
        model,
        datetime.now().strftime('%Y%m%d%H%M')
    )
    return os.path.join(destdir, filename)

def filter_paths(paths, pattern):
    """Get metadata paths containing a regex.
    
    @param paths: list
    @param pattern: str A regular expression
    @returns: list of absolute paths
    """
    prog = re.compile(pattern)
    return [path for path in paths if prog.search(path)]

def all_paths(collection_path, model):
    """Get all .json paths for specified model.
    
    @param collection_path: str Absolute path to collection repo
    @param model: str One of ['collection', 'entity', 'file']
    """
    return util.find_meta_files(
        basedir=collection_path, model=model, recursive=1, force_read=1
    )


def main():

    parser = argparse.ArgumentParser(description=description, epilog=epilog,
                                     formatter_class=argparse.RawDescriptionHelpFormatter)
    parser.add_argument('-b', '--blank', action='store_true', help='Blank CSV, just headers (all fields).')
    parser.add_argument('-B', '--blankr', action='store_true', help='Blank CSV, just headers (required fields only).')
    parser.add_argument('-i', '--ids', help='ID(s) (see help for formatting).')
    parser.add_argument('-I', '--idfile', help='File containing list of IDs, one per line.')
    parser.add_argument('model', help="Model: 'entity' or 'file'.")
    parser.add_argument('collection', help='Absolute path to Collection.')
    parser.add_argument('destdir', help='Absolute path to destination directory.')
    args = parser.parse_args()
    
    if args.idfile and not os.path.exists(args.idfile):
        raise Exception('IDs file does not exist: %s' % args.idfile)
    elif not os.path.exists(args.collection):
        raise Exception('Collection does not exist: %s' % args.collection)
    elif args.model not in identifier.MODELS:
        raise Exception("Bad model name: '%s'" % args.model)
    
    csv = make_csv_path(args.destdir, args.collection, args.model)
    logging.info('Writing to %s' % csv)
    if not os.access(os.path.dirname(csv), os.W_OK):
        raise Exception('Cannot write to %s.' % csv)
    
    start = datetime.now()
    
    logging.info('Gathering entity paths')
    paths = []
    if args.blank or args.blankr:
        pass
    elif args.idfile:  # file containing list of IDs
        paths = make_paths(args.collection, read_id_file(args.idfile))
    elif args.ids:  # ID pattern
        paths = filter_paths(all_paths(args.collection, args.model), args.ids)
    else:  # just get everything
        paths = all_paths(args.collection, args.model)
    if not paths and not (args.blank or args.blankr):
        raise Exception('ERROR: Could not find metadata paths.')
    logging.info('%s matching paths' % len(paths))
    
    batch_export.export(paths, args.model, csv, required_only=args.blankr)
    
    finish = datetime.now()
    elapsed = finish - start
    logging.info('DONE - (%s elapsed) - %s' % (elapsed, csv))
    
    

if __name__ == '__main__':
    main()
