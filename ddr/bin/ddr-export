#!/usr/bin/env python

#
# ddr-export
#

description = """Exports a DDR collection's entities or files to CSV."""

epilog = """
If CSV is not specified a filename will be generated in the form
COLLECTION-MODEL.csv and written to /tmp/.  For example:
    /tmp/ddr-test-123-entity.csv

Sample ID formats:
    ddr-test-123-*            All entities in a collection
    ddr-test-123-1-*          All files in an entity
    ddr-test-123-*            All files in a collection
    ddr-test-123-[1-5,7-8,10] Ranges of entities

Example:

    $ ddr-export entity /var/www/media/base/ddr-testing-123 /tmp
    $ ddr-export file /var/www/media/base/ddr-testing-123 /tmp

ddr-export"""


import argparse
from datetime import datetime
import logging
import os
import re
import sys

from DDR import batch_export
from DDR import models
from DDR import identifier
from DDR import util

logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s %(levelname)-8s %(message)s',
    stream=sys.stdout,
)


def parse_ids(text):
    """Parses IDs arg and returns list of IDs.
    
    ddr-test-123-*            All entities in a collection
    ddr-test-123-1-*          All files in an entity
    ddr-test-123-*            All files in a collection
    ddr-test-123-[1-5,7-8,10] Ranges of entities
    
    TODO Seriously? Can't we just pass in a regex?
    
    @param text: str
    @returns: list
    """
    ids = []
    if ('[' in text) and (']' in text):
        f0 = text.split('[')[0]
        fids = text.split('[')[1].split(']')[0]
        fids1 = fids.split(',')
        for x in fids1:
            if '-' in x:
                lo,hi = x.split('-')
                for y in range(int(lo), int(hi)+1):
                    i = f0 + str(y)
                    ids.append(i)
            else:
                i = f0 + str(x)
                ids.append(i)
    elif '*' in text:
        fid = text
    return ids

def read_id_file(path):
    """Read file and return list of IDs
    
    @param path: str Absolute path to file.
    @returns: list of IDs
    """
    with open(path, 'r') as f:
        text = f.read()
    ids = [line.strip() for line in text.strip().split('\n')]
    return ids

def make_paths(collection_path, model, ids):
    basedir = os.path.dirname(collection_path)
    paths = [
        identifier.Identifier(object_id, basedir).path_abs('json')
        for object_id in ids
    ]
    return paths

def make_csv_path(destdir, collection_path, model):
    filename = '%s-%s-%s.csv' % (
        identifier.Identifier(collection_path).id,
        model,
        datetime.now().strftime('%Y%m%d%H%M')
    )
    return os.path.join(destdir, filename)

def filter_paths(paths, pattern):
    """Get metadata paths containing a regex.
    
    @param paths: list
    @param pattern: str A regular expression
    @returns: list of absolute paths
    """
    prog = re.compile(pattern)
    return [path for path in paths if prog.search(path)]

def all_paths(collection_path, model):
    return util.find_meta_files(
        basedir=collection_path, model=model, recursive=1, force_read=1
    )


def main():

    parser = argparse.ArgumentParser(description=description, epilog=epilog,
                                     formatter_class=argparse.RawDescriptionHelpFormatter)
    parser.add_argument('-i', '--ids', help='ID(s) (see help for formatting).')
    parser.add_argument('-I', '--idfile', help='File containing list of IDs, one per line.')
    parser.add_argument('model', help="Model: 'entity' or 'file'.")
    parser.add_argument('collection', help='Absolute path to Collection.')
    parser.add_argument('destdir', help='Absolute path to destination directory.')
    args = parser.parse_args()
    
    if args.idfile and not os.path.exists(args.idfile):
        raise Exception('IDs file does not exist: %s' % args.idfile)
    elif not os.path.exists(args.collection):
        raise Exception('Collection does not exist: %s' % args.collection)
    elif args.model not in identifier.MODELS:
        raise Exception("Bad model name: '%s'" % args.model)
    
    # Gets Entity or File class
    object_class = identifier.class_for_name(
        identifier.MODEL_CLASSES[args.model]['module'],
        identifier.MODEL_CLASSES[args.model]['class']
    )
    # Gets module from repo_modules
    fields_module = identifier.module_for_name(
        identifier.MODEL_REPO_MODELS[args.model]['module']
    )
    
    csv = make_csv_path(args.destdir, args.collection, args.model)
    logging.info('Writing to %s' % csv)
    if not os.access(os.path.dirname(csv), os.W_OK):
        raise Exception('Cannot write to %s.' % csv)
    
    start = datetime.now()
    
    logging.info('Gathering entity paths')
    paths = []
    if args.idfile:  # file containing list of IDs
        paths = make_paths(args.collection, args.model, read_id_file(args.idfile))
    elif args.ids:  # ID pattern
        paths = filter_paths(all_paths(args.collection, args.model), args.ids)
    else:  # just get everything
        paths = all_paths(args.collection, args.model)
    if not paths:
        raise Exception('ERROR: Could not find metadata paths.')
    logging.info('%s matching paths' % len(paths))
    
    batch_export.export(paths, object_class, fields_module, csv)
    
    finish = datetime.now()
    elapsed = finish - start
    logging.info('DONE - (%s elapsed) - %s' % (elapsed, csv))
    
    

if __name__ == '__main__':
    main()
